{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8144582-28c4-44d0-a14d-8148e50a5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the hyperspectral data\n",
    "hyperspectral_data = scipy.io.loadmat(r\"C:\\Users\\Soham\\Downloads\\Hyper1.mat\")\n",
    "hyperspectral_data = hyperspectral_data['img']  # Ensure the key is correct\n",
    "height, width, bands = hyperspectral_data.shape\n",
    "\n",
    "# Fixing the filtering issue (selecting all bands for now)\n",
    "# To filter specific bands, use indexing or other criteria.\n",
    "filtered_data = hyperspectral_data  # No filtering for now\n",
    "\n",
    "print(f\"Shape after filtering: {filtered_data.shape}\")\n",
    "\n",
    "# Ensure the band index is valid\n",
    "band_index = 10  # Change to a valid index between 0 and bands-1\n",
    "if band_index < 0 or band_index >= bands:\n",
    "    raise ValueError(f\"Invalid band index: {band_index}. Must be between 0 and {bands-1}.\")\n",
    "\n",
    "# Extract and display a specific band\n",
    "band = filtered_data[:, :, band_index]\n",
    "plt.imshow(band)\n",
    "plt.colorbar()\n",
    "plt.title(f'Filtered Hyperspectral Image - Band {band_index}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6e539-75d2-4327-afa5-535472ef6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have to run\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "input_dim = 224  # Background feature size\n",
    "#have to try reducing this \n",
    "latent_dim = 64  # Latent vector size \n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "#try \n",
    "lr = 0.0002\n",
    "\n",
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class LatentDiscriminator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(LatentDiscriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Discriminator for reconstructed input\n",
    "class ReconstructionDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ReconstructionDiscriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(input_dim, latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim, input_dim).to(device)\n",
    "latent_discriminator = LatentDiscriminator(latent_dim).to(device)\n",
    "reconstruction_discriminator = ReconstructionDiscriminator(input_dim).to(device)\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "opt_encoder_decoder = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "opt_latent_discriminator = optim.Adam(latent_discriminator.parameters(), lr=lr)\n",
    "opt_reconstruction_discriminator = optim.Adam(reconstruction_discriminator.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d404d2-8446-4972-a1b9-6f57617adfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the encoder and decoder models\n",
    "encoder.load_state_dict(torch.load(\"encoder_new.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"decoder_new.pth\"))\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "\n",
    "# Assuming DTest is your hyperspectral test data with shape (400, 400, 189)\n",
    "# Reshape the test data to be (400*400, 189) for feeding into the model\n",
    "test_data = filtered_data.reshape(-1, 224)  # Shape will be (160000, 189) (flatten each pixel)\n",
    "\n",
    "# Convert the reshaped data to a tensor and move it to the appropriate device\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32).to(device)\n",
    "\n",
    "# Pass the test data through the encoder and decoder\n",
    "with torch.no_grad():\n",
    "    z_test = encoder(test_data_tensor)  # Get the encoded representation\n",
    "    x_reconstructed = decoder(z_test)  # Reconstruct the hyperspectral data\n",
    "\n",
    "# Compute the reconstruction error (Mean Squared Error) per pixel\n",
    "reconstruction_error = torch.mean((test_data_tensor - x_reconstructed) ** 2, dim=1)\n",
    "\n",
    "# Set a threshold for anomaly detection (e.g., 95th percentile of the reconstruction error)\n",
    "threshold = torch.quantile(reconstruction_error, 0.95)\n",
    "\n",
    "# Detect anomalies (where reconstruction error exceeds the threshold)\n",
    "anomalies = reconstruction_error > threshold\n",
    "\n",
    "# Reshape the anomalies to match the spatial dimensions of the image (400, 400)\n",
    "reshaped_anomalies = anomalies.cpu().numpy().reshape(2085, 682)\n",
    "\n",
    "# Visualize the anomalies in the hyperspectral image\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(reshaped_anomalies, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Detected Anomalies in Hyperspectral Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6601561-f005-4c78-a0a2-cafd6771ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supression by min size\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import label, find_objects\n",
    "\n",
    "# Load your anomaly map (e.g., 'reshaped_anomalies' from the output above)\n",
    "anomaly_map = reshaped_anomalies  # Assuming this is your binary map (400x400)\n",
    "\n",
    "# Label connected components\n",
    "labeled_map, num_features = label(anomaly_map)\n",
    "\n",
    "# Filter out small components\n",
    "size_threshold = 30  # Adjust this threshold based on the size of your plane\n",
    "filtered_map = np.zeros_like(labeled_map)\n",
    "\n",
    "for i in range(1, num_features + 1):\n",
    "    region = (labeled_map == i)\n",
    "    if np.sum(region) >= size_threshold:\n",
    "        filtered_map[region] = 1\n",
    "\n",
    "# Visualize the filtered anomaly map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(filtered_map, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Filtered Anomalies (Large Structures Only)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de84e9f-cc9a-45b1-90f3-24aea7c43d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10889100-2723-41ea-8ff5-1ce6c036df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example maps\n",
    "\n",
    "# Total elements (size of the map)\n",
    "total_elements = map.size\n",
    "\n",
    "# Correct matches (where filtered_map matches map)\n",
    "matching_elements = np.sum(filtered_map == map)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (matching_elements / total_elements) * 100\n",
    "\n",
    "# Display the result\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ce594-2678-42ee-83e7-c8be37056672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ye gaussian blur wala hai,check kar agar op close hai kya koi ek use karege,sigma and threshold change karo \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import remove_small_objects\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def refine_connected_components(binary_anomaly_map, size_threshold=50):\n",
    "    \"\"\"\n",
    "    Refines anomaly map by removing small connected components based on size threshold.\n",
    "    \"\"\"\n",
    "    labeled_map = label(binary_anomaly_map)\n",
    "    refined_map = np.zeros_like(binary_anomaly_map)\n",
    "\n",
    "    for region in regionprops(labeled_map):\n",
    "        if region.area >= size_threshold:\n",
    "            for coords in region.coords:\n",
    "                refined_map[coords[0], coords[1]] = 1\n",
    "\n",
    "    return refined_map\n",
    "\n",
    "# Assuming filtered_anomaly_map and map are defined (map = ground truth)\n",
    "\n",
    "# Test size_thresholds from 10 to 100 in steps of 10\n",
    "best_accuracy = 0\n",
    "best_threshold = 0\n",
    "results = {}\n",
    "\n",
    "for size_threshold in range(10, 110, 10):\n",
    "    # Step 1: Refine Anomaly Map\n",
    "    refined_map = refine_connected_components(binary_anomaly_map, size_threshold=size_threshold)\n",
    "    \n",
    "    # Step 2: Optional Smoothing and Re-thresholding\n",
    "    sigma = 2\n",
    "    smoothed_map = gaussian_filter(refined_map.astype(float), sigma=sigma)\n",
    "    threshold = 0.3\n",
    "    final_map = (smoothed_map > threshold).astype(int)\n",
    "    \n",
    "    # Step 3: Compute Metrics\n",
    "    TP = np.sum((final_map == 1) & (map == 1))  # True Positives\n",
    "    TN = np.sum((final_map == 0) & (map == 0))  # True Negatives\n",
    "    FP = np.sum((final_map == 1) & (map == 0))  # False Positives\n",
    "    FN = np.sum((final_map == 0) & (map == 1))  # False Negatives\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    results[size_threshold] = accuracy\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = size_threshold\n",
    "\n",
    "    print(f\"Size Threshold: {size_threshold}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display the best results\n",
    "print(\"\\nBest Results:\")\n",
    "print(f\"Best Size Threshold: {best_threshold}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Visualize the best anomaly map\n",
    "best_refined_map = refine_connected_components(filtered_anomaly_map, size_threshold=best_threshold)\n",
    "smoothed_best_map = gaussian_filter(best_refined_map.astype(float), sigma=2)\n",
    "final_best_map = (smoothed_best_map > 0.5).astype(int)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(final_best_map, cmap='gray')\n",
    "plt.title(f'Refined Anomaly Map (Best Threshold = {best_threshold})')\n",
    "plt.xlabel('Pixel X-axis')\n",
    "plt.ylabel('Pixel Y-axis')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553579a-e337-4d4e-ad6e-0c6036022a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SIH_gpu)",
   "language": "python",
   "name": "sih_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
